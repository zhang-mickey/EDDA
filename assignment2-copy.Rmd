---
title: "Assignment2 - Group25"
author: "Yinghao Luo, Zheyuan Zhang, Yujie Cao"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# only round 3
options(digits = 3)

knitr::opts_chunk$set(fig.show='hold')
knitr::opts_chunk$set(fig.height = 2.5)
```

## Exercise 1

**a** In order to conduct linear regression later,we need to check if the dataset meet the model assumption. Histogram and barplot have been generated to illustrate the relationship between PClass, Sex, Age and Survived. From the figures, we can know that people in the 3rd class are the majority with not survived status. The number of males were not survived is much higher than that of females. In terms of the age distribution, we can know that most people living with 20-30 years old survived, while most of them in this age period did not survive.

```{r}
data = read.table('titanic.txt', header = TRUE)
table_pclass_survived <- table(data$Survived, data$PClass)
table_sex_survived <- table(data$Survived, data$Sex)
```

```{r, echo=FALSE, fig.width= 12, fig.height= 4}
par(mfrow = c(1,2))
barplot(table_pclass_survived, beside = TRUE,
        col=c("blue", "red"), 
        main="PClass vs Survived", 
        xlab="PClass", ylab="Count", 
        legend.text=c("Not Survived", "Survived"), 
        args.legend=list(title="Survival Status", x="topleft"))

barplot(table_sex_survived, beside = TRUE,
        col=c("blue", "red"), 
        main="Sex vs Survived", 
        xlab="Sex", ylab="Count", 
        legend.text=c("Not Survived", "Survived"), 
        args.legend=list(title="Survival Status", x="topleft"))

survived_data <- data[data$Survived == 1, ]
not_survived_data <- data[data$Survived == 0, ]

hist(survived_data$Age, 
     breaks=seq(0, 80, by=10), 
     col="red",
     xlim=c(0, 80), 
     main="Age Distribution with survival", 
     xlab="Age", 
     ylab="Frequency", 
     border="black")


hist(not_survived_data$Age, 
     breaks=seq(0, 80, by=10),
     col="blue",
     xlim=c(0, 80), 
     main="Age Distribution with not survival", 
     xlab="Age", 
     ylab="Frequency", 
     border="black")
```

According to the results from the logistic regression model, we can see all the variables with p\<0.05, this means all of them have the significant impact on the Survived. Besides, the estimated odds is exp{3.760 - 1.292\*PClass2nd-2.521\*PClass3rd-0.0392\*Age-2.631\*Sexmale}. To be more specific, people in the 2nd class and 3rd class are more likely to not survive compared to 1st class. In addition, people with older age are more likely to not survive. Male is more likely to not survive compared to female.

```{r}
titanic_lr_model <- glm(Survived ~ PClass + Age + Sex, data=data, family=binomial)
summary(titanic_lr_model)
```

**b**

In order to test if there is interaction between age and sex, pclass, we can use logistic model and ANCOVA. Therefore, the last p-value is 0.558, which is higher than 0.05. This means that there is no interaction between age and pclass. Besides, according to the last p-value of glm_age_sex, it is smaller than 0.05, which indicates that there is interaction between age and sex.

```{r}
glm_age_pclass <- glm(Survived ~ PClass + Age + Sex+ Age:Sex+Age:PClass, data=data, family=binomial)
anova(glm_age_pclass,test="Chisq")

glm_age_sex <- glm(Survived ~ Age * Sex, data=data, family=binomial)
anova(glm_age_sex,test="Chisq")
```

After knowing the interaction above, we can determine our model as follows. From p-values, we can know Age and Sexmale are not significant. Since the AIC of this interaction model is lower, we can choose it as our predict model. Then, we can calculate the estimate for the probability of survival for each pair of PClass and Sex for a 55-year-old person.

```{r}
model <- glm(Survived ~ PClass + Age + Sex + Age * Sex, data = data, family=binomial)
summary(model)
```

```{r}
df <- expand.grid(
  PClass = factor(c("1st", "2nd", "3rd"), levels = c("1st", "2nd", "3rd")),
  Sex = factor(c("female", "male"), levels = c("female", "male")),
  Age = 55
)

predict_probs <- predict(model, newdata = df, type = "response")

df$Survival_Prob <- predict_probs
df
```

**c**
We can do the prediction using a machine learning based method.We need to split the dataset in order to do quality measure.Category factor also needed to be encoded.

**d**

Since Sex and Survived will generate a 2X2 table, we can use Fisher's exact test. According to the p-values, we can know both PClass and Sex have significant impacts on Survived.

```{r}
chisq_PClass <- chisq.test(table_pclass_survived)
chisq_PClass

chisq_Sex <- fisher.test(table_sex_survived)
chisq_Sex
```

**e** The contingency table test in d is not wrong, since it can be used to test the relationship of Survived&PClass and Survive&Sex. The contingency table is an easier way to test if two factors are independent. However, the contingency table can only process categorical data, but not continuous data. In addition, the contingency table cannot predict, it can only test of these two factors are independent.

In terms of logistic regression model, it can simultaneously process multiple variables (more than 2), while contingency table can only involve two variables. It can also discuss the interaction between variables, while contingency tables cannot. However, logistic regression model assumes that there is a linear relationship between the independent and dependent variables. And It requires many data for better predicted results.

## Exercise 2

**a** According to the results from poisson model, we can observe that only oligarchy, pollib and parties have significant impact on the miltcoup, since their P-values are lower than 0.05. Besides, the oligarchy and parties show a positive correlation with milycoup, while pollib illustrates a negative correlation.

```{r}
coups_data = read.table('coups.txt', header = TRUE)

coupsglm = glm(miltcoup~oligarchy + pollib + parties + pctvote + popn + size + numelec + numregim, family = poisson, data = coups_data)

summary(coupsglm)
```

**b** By applying the step down, it is known from the result that only oligarchy, pollib and parties are significant. We can first remove the variable with the largest p-value: numregim. After removing this, we go back to step 2, test all the remaining variables by using the t-test. Then, we remove numelec, size, pctvote and popn sequentially as each summary result shows.

```{r}
summary(lm(miltcoup~oligarchy + pollib + parties + pctvote + popn + size + numelec + numregim, data = coups_data))
```

```{r}
summary(lm(miltcoup~oligarchy + pollib + parties + pctvote + popn + size + numelec, data = coups_data))
```

```{r}
summary(lm(miltcoup~oligarchy + pollib + parties + pctvote + popn + size, data = coups_data))
```

```{r}
summary(lm(miltcoup~oligarchy + pollib + parties + popn + size, data = coups_data))
```

```{r}
summary(lm(miltcoup~oligarchy + pollib + parties + popn, data = coups_data))
```

Finally, after remove the variables by using the step down method, we will get 3 remaining variables, which are all significant. They are oligarchy, pollib and parties.

The step down method shares same results with poisson regression in (a)

```{r}
summary(lm(miltcoup~oligarchy + pollib + parties, data = coups_data))
```

**c**

The model we get in (b) is: miltcoup = 1.626 + 0.153 \* oligarchy + 0.042 \* parties - 0.954 \* pollib with R square = 0.513. In this case, we can calculate the average of oligarchy and parties respectively. Then, input them into the predict function. The prediction of each pollib is: The pollib level is 0, the predict result is 3.14. The pollib level is 1, the predict result is 2.19. The pollib level is 2, the predict result is 1.23. We can discover that as the pollib level grows, the miltcoup decreases. It means that number of successful military coups is negatively correlated to political liberalization level.

```{r}
oligarchy_avg <- mean(coups_data$oligarchy)
parties_avg <- mean(coups_data$parties)

pollib_levels <- c(0, 1, 2)


predictions <- sapply(pollib_levels, function(pollib_value) {
  miltcoup_pred <- 1.626 + 0.153 * oligarchy_avg  + 0.042 * parties_avg - 0.954 * pollib_value
  return(miltcoup_pred)
})

result <- data.frame(Pollib = pollib_levels, Prediction = predictions)

result

```

## Exercise 3

From the scatter plots, we can know that weight and viscosity show non-linear relation with Time.

```{r, echo=FALSE, fig.width= 12, fig.height= 4}
library(MASS)
data(stormer)
par(mfrow = c(1,2))
#plot(stormer$Wt, stormer$time, xlab="Weight", ylab="Time", main="The scatter plot between Weight and Time")

#plot(stormer$Viscosity, stormer$time, xlab="Viscosity", ylab="Time", main="Scatter plot between Viscosity and Time")

pairs(stormer, main="Scatterplot Matrix for Stormer Viscometer Data")


```

```{r}
stormer_linear = lm(Time ~ Viscosity + Wt, data = stormer)

summary(stormer_linear)
```

```{r}
form = as.formula(Time ~ theta1 * Viscosity / (Wt - theta2))
non_linear = nls(form, data = stormer, start = c(theta1=0.622, theta2 = -1.693))

non_linear
```

```{r, echo=FALSE, fig.width= 12, fig.height= 4}

par(mfrow = c(1,2))

plot(stormer$Wt, stormer$time, xlab="Weight", ylab="Time", main="The scatter plot between Weight and Time")
lines(stormer$Wt, predict(non_linear, newdata = stormer), col="red", lwd=2)


plot(stormer$Viscosity, stormer$time, xlab="Viscosity", ylab="Time", main="The scatter plot between Viscosity and Time")
lines(stormer$Viscosity, predict(non_linear, newdata = stormer), col="red", lwd=2)
```
